summary(songs)
SongsTest = subset(songs,year> 2009 )
str(SongsTrain)
nonvars = c("year","songtitle","artistname", "songID", "artistID")
SongsTrain = SongsTrain[,!(names(SongsTrain)%in% nonvars)]
SongsTest = SongsTest[,!(names(SongsTest)%in% nonvars)]
model1 = glm(Top10 ~ .,data = SongsTrain, family = binomial)
summary(model1)
cor(songs$loudness,songs$energy)
cor(SongsTrain$loudness,SongsTrain$energy)
nonvars2 = c("year","songtitle","artistname", "songID", "artistID", "loudness")
SongsTrain2 = SongsTrain[,!(names(SongsTrain)%in% nonvars)]
summary(SongsTrain2)
str(SongsTrain2)
SongsTrain2 = SongsTrain[,!(names(SongsTrain)%in% nonvars2)]
str(SongsTrain2)
model2 = glm(Top10 ~ . , data = SongsTrain2, family = binomial)
str(model2)
summary(model2)
nonvars3 = c("year","songtitle","artistname", "songID", "artistID", "energy")
SongsTrain3 = SongsTrain[,!(names(SongsTrain)%in% nonvars3)]
model3 = glm(Top10 ~ . , data = SongsTrain3, family = binomial)
model3
summary(model3)
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
summary(SongsLog2)
SongsLog3 = glm(Top10 ~ . -energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
TestPedictions = predict(SongsLog3, newdata = SongsTest, type="response")
table(TestPredictions)
table(TestPedictions)
table(TestPedictions$Top10)
table(SongsTest$Top10,TestPedictions>0.5)
table(SongsTest$Top10,TestPedictions>0.45)
19/(40+19)
(309+19)/(309+19+40+5)
table(SongsTrain$Top10)
table(SongsTest$Top10)
314/(314+59)
table(SongsTest$Top10,TestPedictions>0.45)
(309+19)/(309+19+5+40)
19/(19+40)
309/(309+5)
parole = read.csv("parole.csv")
str(parole)
table(parole$violater)
table(parole$violator)
summary(parole)
str(parole)
table(parole$violator)
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
summary(parole$state)
summary(parole)
str(parole)
summary(parole$state)
summary(parole$crime)
set.seed(144)
library(caTools)
split = sample.split(parole$violator, SplitRatio = 0.7)
train = subset(parole,split ==TRUE)
split
test = subset(parole,split ==FALSE)
paroleLog = glm(violator ~ .,data = parole, family="binomial")
summary(paroleLog)
paroleLog = glm(violator ~ .,data =train, family="binomial")
summary(paroleLog)
str(parole)
table(parole$state)
predictParole = predict(paroleLog, newdata = test, type = "response")
max(predictParole)
table(test$violator,predictParole > 0.5)
12/(11+12)
167/(167+12)
(12+167)/(12+167+12+11)
table(train$violator)
table(test$violator)
summary(paroleLog)
table(test$violator,predictParole > 0.5)
table(train$violator,predictParole > 0.5)
table(test$violator)
table(train$violator)
table(test$violator, sign(test$violator))
table(train$violator)
table(train$violator, sign(train$violator))
library(ROCR)
ROCRpredparole = prediction(predictParole, test$violator)
as.numeric(performance(ROCRpredparole, "auc")@y.values)
loans = read.csv("loans.csv")
table(loans$not.fully.paid)
summary(loans)
missing = subset(loans, is.na(log.annual.inc) | is.na(days.with.cr.line) | is.na(revol.util) | is.na(inq.last.6mths) | is.na(delinq.2yrs) | is.na(pub.rec))
nrow(missing)
str(missing)
summary(loans)
str(loans)
library(mice)
set.seed(144)
vars.for.imputation = setdiff(names(loans), "not.fully.paid")
imputed = complete(mice(loans[vars.for.imputation]))
loans[vars.for.imputation] = imputed
summary(loans)
loansImp = read.csv("loans_imputed.csv")
summary(loansImp)
str(loansImp)
str(loans)
library(caTools)
set.seed(144)
split = sample.split(loans$not.fully.paid,0.7)
train = subset(loans,split ==TRUE)
test = subset(loans,split ==FALSE)
modelLoans = glm(not.fully.paid ~ ., data = train, family = "binomial")
summary(modelLoans)
predictLoans = predict(modelLoans, newdata = test, type="response")
summary(predictLoans)
str(predictLoans)
loans
loans$predicted.risk = predictLoans
test$predicted.risk = predictLoans
summary(test)
str(test)
table(test$not.fully.paid,test$predicte)
table(test$not.fully.paid,test$predicted.risk >0.5)
2403/(2403+13+457)
table(test$not.fully.paid)
2403/2413
2413/(2413+460)
library(ROCR)
pred = prediction(test$predicted.risk, test$not.fully.paid)
as.numeric(performance(pred, "auc")@y.values)
modelLoansbivariate = glm(not.fully.paid ~ int.rate, data = train, family = "binomial")
summary(modelLoansbivariate)
predictLoansbivariate = predict(modelLoansbivariate, newdata = test, type = "response")
which.max(predictLoansbivariate)
.max(predictLoansbivariate)
max(predictLoansbivariate)
table(test$not.fully.paid, predictLoansbivariate >0.5)
pred = prediction(predictLoansbivariate, test$not.fully.paid)
as.numeric(performance(pred, "auc")@y.values)
10* exp(.06*3)
test$profit = exp(test$int.rate*3) - 1
str(test$profit)
test$profit[test$not.fully.paid ==1] == -1
test$profit[test$not.fully.paid ==1] = -1
str(test$profit)
table(test$profit ==1)
table(test$profit ==-1)
max(test$profit)
max(test$profit)*10
max(test$int.rate)
highInterest = subset(test, int.rate>=0.15)
str(highInterest)
mean(highInterest$profit)
table(highInterest$not.fully.paid == 1)
110/(110+327)
tapply(highInterest$profit, highInterest$not.fully.paid, sum,1)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
cutoff
selectedLoans = subset(highInterest,predicted.risk <=0.17695 )
selectedLoans = subset(highInterest,predicted.risk <= cutoff )
str(selectedLoans)
sum(selectedLoans$profit)
table(highInterest$not.fully.paid ==1)
table(selectedLoans$not.fully.paid ==1)
nrow(baseball)
table(baseball$Year)
length(table(baseball$Year))
baseball = subset(baseball, Playoffs ==1)
str(baseball)
table(baseball$Year, baseball$Playoffs)
table(table(baseball$Year))
table(baseball$Year)
PlayoffTable = table(baseball$Year)
names(PlayoffTable)
str(PlayoffTable)
baseball$NumCompetitors = PlayoffTable[as.character(baseball$Year)] 
baseball$NumCompetitors
table(baseball$NumCompetitors ==8)
baseball$RankPlayoffs == 1
baseball$WorldSeries = as.numeric(baseball$RankPlayoffs == 1)
table(baseball$WorldSeries ==0)
mo = glm(WorldSeries~ Year, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ RS, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ RA, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ W, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ OBP, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ SLG, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ BA, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ RankSeason, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ OOBP, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ OSLG, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ NumCompetitors, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ League, data = baseball, family="binomial")
summary(mo)
mo = glm(WorldSeries~ Year+NumCompetitors+RankSeason+RA, data = baseball, family="binomial")
summary(mo)
cor(baseball)
cor(baseball[c("Year","NumCompetitors","RankSeason","RA")])
moYear = glm(WorldSeries~ Year, data = baseball, family="binomial")
moNC = glm(WorldSeries~ NumCompetitors, data = baseball, family="binomial")
moRankSeason = glm(WorldSeries~ RankSeason, data = baseball, family="binomial")
moRA = glm(WorldSeries~ RA, data = baseball, family="binomial")
moYearRA = glm(WorldSeries~ RA+Year, data = baseball, family="binomial")
moYear = glm(WorldSeries~ Year+RankSeason, data = baseball, family="binomial")
moYear = glm(WorldSeries~ Year, data = baseball, family="binomial")
moYearRankSeason = glm(WorldSeries~ Year+RankSeason, data = baseball, family="binomial")
moYearNC = glm(WorldSeries~ Year+NumCompetitors, data = baseball, family="binomial")
moRARankSeason = glm(WorldSeries~ RA+RankSeason, data = baseball, family="binomial")
moRANC = glm(WorldSeries~ RA+NumCompetitors, data = baseball, family="binomial")
moRankSeasonNC = glm(WorldSeries~ RankSeason+NumCompetitors, data = baseball, family="binomial")
summary(moRankSeasonNC)
14/20
stevens = read.csv("stevens.csv")
str(stevens)
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
train = subset(stevens, spl ==TRUE)
test = subset(stevens, spl == FALSE)
library(cart)
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
StevensTree = rpart(Reverse~ Circuit+Issue+Petitioner+LowerCourt+Unconst, data= train, method = "class")
StevensTree = rpart(Reverse~ Circuit+Issue+Petitioner+LowerCourt+Unconst, data= train, method = "class", minbucket = 25)
prp(StevensTree)
StevensTree = rpart(Reverse~ Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst, data= train, method = "class", minbucket = 25)
prp(StevensTree)
PredictCART = predict(StevensTree, newdata=test, type="class")
table(test$Reverse, PredictCART)
library(ROCR)
PredictROC = predict(StevensTree, newdata = test)
PredictROC
pred = prediction(PredictROC[,2], test$Reverse)
perf = performance(pred,"tpr","fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
StevensTree2 = rpart(Reverse~ Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst, data= train, method = "class", minbucket = 5)
prp(StevensTree2)
prp(StevensTree)
prp(StevensTree2)
StevensTree3 = rpart(Reverse~ Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst, data= train, method = "class", minbucket = 100)
prp(StevensTree3)
install.packages("randomForest")
library("randomForest")
StevensForest = randomForest(Reverse~Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst,data = train, nodesize = 25, ntree=200)
train$Reverse = as.factor(train$Reverse)
test$Reverse = as.factor(test$Reverse)
StevensForest = randomForest(Reverse~Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst,data = train, nodesize = 25, ntree=200)
summary(StevensForest)
PredictForest = predict(StevensForest,newdata = test)
table(test$Reverse,, PredictForest)
table(test$Reverse, PredictForest)
(39+76)/(39+76+38+17)
set.seed(100)
StevensForest = randomForest(Reverse~Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst,data = train, nodesize = 25, ntree=200)
PredictForest = predict(StevensForest,newdata = test)
table(test$Reverse, PredictForest)
(43+74)/(43+74+19+34)
set.seed(200)
StevensForest = randomForest(Reverse~Circuit+Issue+Petitioner+Respondent+LowerCourt+Unconst,data = train, nodesize = 25, ntree=200)
PredictForest = predict(StevensForest,newdata = test)
table(test$Reverse, PredictForest)
(44+76)/(44+76+33+17)
library(caredt)
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
Claims = read.csv("ClaimsData.csv")
str(Claims)
table(Claims$bucket2009)/nrows(Claims)
table(Claims$bucket2009)/nrow(Claims)
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
mean(ClaimsTrain$age)
table(ClaimsTrain$diabetes)
table(ClaimsTrain$diabetes)/nrow(ClaimsTrain)
table(ClaimsTest$bucket2009,ClaimsTest$bucket2008)
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5))
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
as.matrix(table(ClaimsTest$bucket2009,ClaimsTest$bucket2008))* PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009,ClaimsTest$bucket2008))* PenaltyMatrix)/nrow(ClaimsTest)
table(ClaimsTest$bucket2009)
122978/nrow(ClaimsTest)
sum(as.matrix(122978/nrow(ClaimsTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(PenaltyMatrix * as.matrix(122978/nrow(ClaimsTest)))/nrow(ClaimsTest)
PenaltyMatrix = matrix(c(0,1,2,3,4), byrow=TRUE, nrow=5)
sum(as.matrix(122978/nrow(ClaimsTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(122978/nrow(ClaimsTest))*(PenaltyMatrix)')/nrow(ClaimsTest)
)
))
sum(as.matrix(122978/nrow(ClaimsTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009))* PenaltyMatrix)/nrow(ClaimsTest)
table(ClaimsTest$bucket2009)
as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix)
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix)/nrow(ClaimsTest)
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009))'*PenaltyMatrix)/nrow(ClaimsTest)
)
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009,rep(1,nrow(ClaimsTest))))*PenaltyMatrix[,1])/nrow(ClaimsTest)
library(rpart)
library(rpart.plot)
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
prp(ClaimsTree)
PredictTest = predict(ClaimsTree, newdata = ClaimsTest,method = "class")
table(ClaimsTest$bucket2009, PredictTest)
PredictTest = predict(ClaimsTree, newdata = ClaimsTest,type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
boston = read.csv("boston.csv")
str(boston)
plot(boston$LAT, boston$LAT)
plot(boston$LAT, boston$LON)
points(boston$LON[boston$CHAS==1],col="blue",pch=19)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS ==1]col="blue",pch=19)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS ==1],col="blue",pch=19)
plot(boston$LAT, boston$LON)
points(boston$LON[boston$CHAS==1],boston$LAT[boston$CHAS ==1],col="blue",pch=19)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
plot(boston$LAT, boston$LON)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
points(boston$LON[boston$TRACT==1], boston$LAT[boston$TRACT==1], col="red", pch=19)
points(boston$LON[boston$TRACT==35311], boston$LAT[boston$TRACT==3531], col="red", pch=19)
points(boston$LON[boston$TRACT==3531], boston$LAT[boston$TRACT==3531], col="red", pch=19)
library(ggplot2)
points(boston$LON[boston$TRACT==3531], boston$LAT[boston$TRACT==3531], col="red", pch=19)
str(boston)
plot(boston$LAT, boston$LON)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
movies = read.table("movieLens.txt", header=FALSE, sep="|",quote="\"")
movies = read.table("movielens.txt", header=FALSE, sep="|",quote="\"")
colnames(movies) = c("ID", "Title", "ReleaseDate", "VideoReleaseDate", "IMDB", "Unknown", "Action", "Adventure", "Animation", "Childrens", "Comedy", "Crime", "Documentary", "Drama", "Fantasy", "FilmNoir", "Horror", "Musical", "Mystery", "Romance", "SciFi", "Thriller", "War", "Western")
str(movies)
movies$ID = NULL
movies$ReleaseDate = NULL
movies$VideoReleaseDate = NULL
movies$IMDB = NULL
movies = unique(movies)
str(movies)
sum(movies$Comedy)
sum(movies$Western)
sum(movies$Romance)+sum(movies$Drama)
sum(movies$Drama)
sum(movies$Romance)
244+716
sum(movies$Romance) and sum(movies$Drama)
sum(movies$Romance) && sum(movies$Drama)
table(movies$Romance,movies$Drama)
distances = dist(movies[2:20], method = "euclidean")
clusterMovies = hclust(distances, method = "ward")
plot(clusterMovies)
clusterGroups = cutree(clusterMovies, k = 10)
clusterGroups = cutree(clusterMovies, k = 10)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
clusterGroups = cutree(clusterMovies, k = 2)
plot(clusterMovies)
clusterGroups = cutree(clusterMovies, k = 2)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
tapply(movies$Adventure, clusterGroups, mean)
tapply(movies$Animation, clusterGroups, mean)
tapply(movies$Comedy, clusterGroups, mean)
tapply(movies$Crime, clusterGroups, mean)
tapply(movies$Mystery, clusterGroups, mean)
tapply(movies$Thriller, clusterGroups, mean)
tapply(movies$Horror, clusterGroups, mean)
tapply(movies$Documentary, clusterGroups, mean)
tapply(movies$Drama, clusterGroups, mean)
tapply(movies$FilmNoir, clusterGroups, mean)
tapply(movies$Western, clusterGroups, mean)
tapply(movies$SciFi, clusterGroups, mean)
WHO = read.csv("WHO.csv")
str(WHO)
plot(WHO$GNI, WHO$FertilityRate)
install.packages("ggplot2")
library(ggplot2)
scatterplot = ggplot(WHO, aes(x = GNI, y = FertilityRate))
scatterplot = ggplot(WHO, aes(x = GNI, y = FertilityRate))
scatterplot + geom_point()
scatterplot + geom_line()
scatterplot + geom_line()
scatterplot + geom_line()
scatterplot + geom_point()
scatterplot + geom_point(color = "blue", size = 3, shape = 17)
ggplot(WHO, aes(x = FertilityRate, y = Under15)) + geom_point()
ggplot(WHO, aes(x = FertilityRate, y = Under15, color = Region)) + geom_point()
ggplot(WHO, aes(x = FertilityRate, y = Under15, color = Region)) + geom_point(),scale_color_brewer(palette="Dark2")
ggplot(WHO, aes(x = FertilityRate, y = Under15, color = Region)) + geom_point()+scale_color_brewer(palette="Dark2")
ggplot(WHO, aes(x = FertilityRate, y = Under15, color = Region)) + geom_point()+scale_color_brewer(palette="Dark2")
ggplot(WHO, aes(x = FertilityRate, y = Under15, color = Region)) + geom_point()+scale_color_brewer(palette="Dark2")
ggplot(murderMap, aes(x = long, y = lat, group=group, fill = GunOwnership)) + geom_polygon(color="black") + scale_fill_gradient(low = "black", high = "red", guide="legend")
Airlines <- read.csv("AirlineDelay (1).csv")
set.seed(15071)
spl = sample(nrow(Airlines), 0.7*nrow(Airlines))
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
summary(AirlinesTrain)
str(AirlinesTrain)
str(AirlinesTest)
DelayReg = lm(TotalDelay ~ ., data = Airlines)
DelayReg = lm(TotalDelay ~ ., data = AirlinesTrain)
summary(DelayReg)
corr(Airlines)
cor(Airlines)
cor("Airlines")
corr(AirlinesTrain$NumPrevFlights, Airlines$PrevFlightGap)
cor(AirlinesTrain$NumPrevFlights, Airlines$PrevFlightGap)
cor(AirlinesTrain$NumPrevFlights, AirlinesTrain$PrevFlightGap)
cor(AirlinesTrain$OriginAvgWind, AirlinesTrain$OriginWindGust)
predict = predict(DelayReg)
predict = predict(DelayReg,newdata = AirlinesTest)
SSE = sum((predict - AirlinesTest$TotalDelay)^2)
SST = sum((mean(Airlines$TotalDelay) - AirlinesTest$TotalDelay)^2)
SST
SSE
R2 = 1- SSE/SST
R2
SST = sum((mean(AirlinesTrain$TotalDelay) - AirlinesTest$TotalDelay)^2)
SST
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
table(Airlines$DelayClass)
Airlines$TotalDelay = NULL
set.seed(15071)
split = sample.split(Airlines$DelayClass, SplitRatio = 0.7)
library(caTools)
split = sample.split(Airlines$DelayClass, SplitRatio = 0.7)
train = subset(Airlines, split==TRUE)
test = subset(Airlines, split==FALSE)
library(rpart)
library(rpart.plot)
Tree = rpart(DelayClass~., data = Train, method="class")
Tree = rpart(DelayClass~., data = train, method="class")
prp(Tree)
PredictCART = predict(Tree, newdata = train, type = "class")
table(train$DelayClass, PredictCART)
(361+3094)/(314+804+361+3094+188+1806)
3094/(314+804+361+3094+188+1806)
3094/6656
314+804+361+3094+188+1806
3094+188/6567
(3094+188)/6567
PredictCART = predict(Tree, newdata = test, type = "class")
table(test$DelayClass, PredictCART)
(153+1301)/(141+338+153+776+105+1301)
load("eBay.Rdata")
eBay
table(ebay)
table(eBay)
eBay= read.csv("ebay.csv", stringsAsFactors=FALSE)
table(eBay)
table(eBay$sold)
799/(799+2997)
summary(eBay)
table(eBay$size)
eBay$sold = as.factor(eBay$sold)
eBay$condition = as.factor(eBay$condition)
eBay$heel = as.factor(eBay$heel)
eBay$style = as.factor(eBay$style)
eBay$color = as.factor(eBay$color)
eBay$material = as.factor(eBay$material)
set.seed(144)
library(caTools)
spl = sample.split(eBay$sold, 0.7)
train = subset(eBay, spl==TRUE)
test = subset(eBay, spl==FALSE)
testing = subset(eBay, spl==FALSE)
training = subset(eBay, spl==TRUE)
Log = glm(sold ~ biddable+startprice+condition+heel+style+color+material, data=training, family=binomial)
summary(Log)
100*(-0.004)+0.122+0.526+0.229-1.107
predictTrain = predict(Log, type="response")
summary(predictTrain)
predictTrain = predict(Log,newdata = testing, type="response")
summary(predictTrain)
table(training$sold, predictTrain > 0.5)
table(testing$sold, predictTrain > 0.5)
library(ROCR)
ROCRpred = prediction(predictTrain, testing$sold)
as.numeric(performance(ROCRpred, "auc")@y.values)
ROCRpred = prediction(predictTrain, testing$sold)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE)
(1030+92)/(126+92+227+1030)
